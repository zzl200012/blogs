## Notes|DDIA-Sharding

### Motivation

* 提高可扩展性（scale-up）
* 负载均衡

### Overview

* KV Sharding
* Secondary Index Sharding
* Rebalance
* Routing

### Approach

* 键值数据分区

  * Goal：将数据和查询负载尽可能均匀地分布到各个节点上
  * 若分区策略不公平，会导致倾斜，其中负载过高的节点就成为热点
  * 分区策略：
    * Key Range：
      * 通过一块连续的键的范围确定一个分区
      * 区间段不一定均匀：数据本身就不均匀（英文字母&单词）
      * 热点问题：某些访问模式会出现热点（如以时间戳为键，以天为分区，则当天的负载过高），此时需要修改键的定义方式，尽可能将查询负载分散到多个节点上
      * 优化：
        * 手动/自动调整区间边界使数据分布尽可能均匀
        * 分区内按照键有序存储数据（LSMT）从而支持 Range Scan
    * Key Hash：
      * 先让键做一次哈希，再根据哈希值范围确定区间
      * 键无序，丧失范围查询能力
      * 热点问题还没解决
      * 优化：
        * 复合主键：多个列组成复合主键，只有第一列用于 Hash，其他用作范围查询；以社交媒体为例，不同用户可以存在不同分区上（通过 Hash），在他自己的分区里可以按时间戳顺序存储他的消息，这样就可以范围查询某段时间该用户的消息
        * 应用层对热点键缓存

* 二级索引分区

  * 主键（聚簇）索引叶子节点存的是 Entry；非主键（二级）索引叶子节点存的是主键的值
  * 二级索引不能规整地映射到分区中
  * 分区策略：
    * 基于文档的二级索引分区：
      * 还是按照主键范围进行分区，但是在各个分区上单独建立二级索引，这样读取的时候需要查询所有分区，然后对结果进行合并，故该方法亦称为分散/聚集
      * 缺陷：显然查询代价过高，并且查询中引用多个二级索引时很难处理
    * 基于词条的二级索引分区
      * 索引是全局的，并且也根据词条（Term）进行分区，和前面主键分区一样可以取哈希使分布更均匀
      * 对于查询的词条提供范围查询，且不需要分散/聚集所有分区
      * 缺陷：写入慢且复杂，因为单个文档的更新会牵涉到多个分区上的二级索引；需要分布式事务保证索引最新

* 分区再平衡

  * 现实中添加或减少硬件，会导致需要将数据和请求从一个节点转移到另一个节点。这样的迁移过程即为再平衡（rebalance），通常要满足以下条件：
  * 保证均匀分布：平衡之后，负载、数据存储、读写请求能够在集群范围内更均匀分布。
  * 保持可用性：再平衡过程中，数据库可以继续处理客户端的读写请求。
  * 减少数据迁移：避免不必要的负载迁移。
  * 为啥 Sharding 时不能取模？显然当节点数变更时要重新取模，几乎所有数据都要迁移
  * 策略：
    * 令分区数固定且>>节点数
      * 键与分区的映射一开始就确定了，只需要调整分区与节点的关系
      * 缺陷：不够灵活，且分区数难以确定时会很难搞
    * 动态分区
      * 采用类似 B 树的策略，根据数据规模动态创建、合并分区
      * 分区与节点仍是多对一关系
      * 大分区拆分后数据转移到其他节点
      * 缺陷：初始时数据少，只有一个分区，空闲节点多，故需要预分区
    * 按节点比例分区
      * 前面的策略中分区数和节点数都无关，这里让分区数与集群节点数成正比，即每个节点拥有固定数目的分区。当增减节点时选择固定数目的现有分区进行拆分或合并，从而维持前面所述的定义
      * 最符合一致性哈希的定义：why？

* 请求路由

  * 用户发出请求时如何知晓目标节点？本质上也就是服务发现问题

  * 策略：

    * 轮询所有节点，如果命中就处理，否则转发至下一个节点
    * 将所有请求发到一个路由层，再由路由层转发
    * 用户本身就知道分区和节点的对应关系，那没事了

  * 核心问题：做出路由决策的组件如何感知分区与节点的对应关系以及变化

    * 第三方协调服务，如依靠 Zookeeper 进行集群元数据管理
    * 使用 Gossip 协议同步集群状态的变化，结合前面的轮询策略即可，这样做避免了依赖外部的协调服务
    * 其他的共识协议


---

Last updated at 2021.02.10